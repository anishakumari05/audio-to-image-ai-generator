This project implements a live speech-to-image conversion system that combines cutting-edge technologies like fine-tuned Whisper ASR for accurate audio transcription, sentiment-aware NLP for content analysis, and Stable Diffusion for context-driven image generation. The system ensures appropriate outputs by filtering transcriptions based on sentiment analysis, delivering meaningful and relevant visuals. Built as a user-friendly Streamlit application, it supports real-time audio input and seamlessly transforms speech into visually enriched outputs using advanced AI models and frameworks like PyTorch and Hugging Face.
